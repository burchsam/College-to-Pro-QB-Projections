---
title: "College-to-Pro QB Model"
author: "Sam Burch"
date: "2024-00-00"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

**Introduction**

After defining quarterback (QB) success in my previous article, it is now time to project QB play for the top prospects heading into the 2024 NFL draft. Last year, I developed a linear regression model to predict NFL success (defined as a 50-50 composite of EPA/play and average PFF grade). After optimizing with the greedy algorithm and manually *eliminating* collinearity issues, my model had an adjusted R^2 of 0.55. While this was a step in the right direction, there were several issues, mainly overfitting biases, that I will be correcting in this analysis.

**Data Processing**

To start, the dataset had a career minimum of 650 plays and 250 for each season. This restricted the sample size to only 29 QBs. Therefore, this dataset (same as for the previous article) uses 400 min. career plays and 150 min. for each season. This allows us to increase the sample size to 47 and include players who didn't have as many plays due to them being bad. I also reduced the number of college single season plays from 200 to 150. (Keep in mind, the sample size is so small because college data is from 2014-2023. Hence, players like Cam Newton, Andrew Luck, or even Tom Brady won't be studied here. This is perhaps the biggest issue that still hasn't been solved.)

After these restrictions were set, I needed college stats that could be used as potential predictors. The PFF datasets I have access to provide information like big-time-throws, pressure-to-sack-rate, and grades. Not many tweaks were made to these individual stats, however one big change was considering different samples. Not only will I include the career play of these QBs, but I will also include first, last, worst, and best college season summaries. On top of this, the cfbfastR data I used last year only considers a handful of stats. This year, I'm expanding this list to include total EPA, sack plays, and even ground plays (sack or rush). I'm also considering career, first, last, worst, and best season splits.

One key predictor to NFL QB play is draft position. Draft pick has a -0.35 correlation with NFL success (defined as value per game metric, min. 10 games) since 1980. Thus, I will add in pick, round, and age from the nflfastR draft picks package.

Other potential predictors can include combine measures, but they were not considered in this analysis. Tej Seth of Sumer Sports wrote about recent correlations with NFL success *here* (https://sumersports.com/the-zone/nfl-combine-what-influences-production-and-draft-position/).



**Correlations**

This dataset has 193 potential predictors that it is considering. So, let us look at those whose absolute correlation is 0.25 or larger.

Right away, we can see ground EPA is very important. Variants of ground EPA make up the top-3 and five of the top-6. In fact, the top-2 have a correlation above 0.40, which is great for football data. Pressure-to-sack-rate (PTSR) is seventh highest at -0.35, meaning a the lower the better. This all points to pocket awareness -- maximizing sack avoidance and scrambling -- translates to the NFL. (Keep in mind, something like EPA per pressure play is more likely to determine how a QB plays under pressure; this is due to pressures that result in passes. However, I do not have access to pressure play-by-play data.) Average depth of target (ADOT) in their first year shows up surprisingly well at 0.37. This likely points to the importance of arm strength in the NFL. Total EPA and EPA per play have appearances high, which makes sense as these are based on overall production. Lastly, other total statistics -- like TDs, completions, and yards -- signal the importance of experience and productivity.


Draft round and pick were relatively low, at -0.27 and -0.25 respectively, when we know these should be high. If we look at the top correlations with pick, this may provide some traits our models may be missing on.

There are a lot of high correlations here, as nearly 40 other predictors have an absolute correlation above 0.40 with draft pick. The highest, above 0.50, include the following: average pass EPA in best year, total EPA in best year, EPA per play in best year, EPA per rush, and EPA per pass. Across the board, these statistics are production based whether that be through film (PFF grading) or analytics (EPA). This of course makes sense and likely will be more helpful statistics than just looking at sack avoidance. While that may ring true, it is possible NFL teams are underrating the importance of pocket awareness, experience, and maybe even arm strength as these have higher importance to NFL success in this dataset.

**Data Mining**


Let's run through some interesting graphs before we begin modeling. For these, I will look at the 47 NFL QBs in the dataset along with the top-7 2024 draft prospects. In my last article, the 67th percentile was defined as the average starter, so we will continue to use this definition here.




Looking at career production, Williams is atop, with Maye being second in grading and McCarthy being second in efficiency. While good production in college doesn't necessarily translate to NFL production -- look at the mix of blue and red dots in the top right and bottom left -- we know that production is important for draft position. Thus, with draft position being important historically, we know college production should lead to better prospects in general.


Looking at best season production for efficiency and grading, Daniels is by far the best of the 24' prospects. Nix is second, followed by a cluster including Williams, Penix, and McCarthy. Maye & Rattler had elite grading in their best seasons, but efficiency was below average here. Regardless, all of these prospects have had good best seasons, which should be a good sign.


Here, we look at where on the field a QBs efficiency is coming from. The top right (good passing, rushing, and sack avoidance) is where one wants to be. Of the NFL QBs, only three are below average and six are above average. All of the 24' prospects, expect Rattler, are in this quadrant. Also, having good ground efficiency gives QBs a solid floor, since very few above average starters had below average ground efficiency and 8 of the top 9 were above average starters. Nix and Daniels show up the best in ground efficiency giving them a solid floor. Keep in mind though, some of the *successful* QBs with great ground EPA include Hill and Mariota.


The top couple predictors are all dealing with ground efficiency. However, ADOT in a QBs first year is very high as well. As we compare the two, we can see there have only been three failures in the top right quadrant, compared to nine successes.  Williams, McCarthy, Maye, and Penix are all in this area. Nix and Daniels don't have a high ADOT in their first year, however they have the second and third best max total ground EPA respectively. Again, this should lead to a high floor and is a good sign regardless of their ADOT.



Just looking at how QBs deal with pressure in college can tell us a lot. Penix has the best PTSR in this entire dataset. Nix also doesn't take many sacks and has the added benefit of his rushing. While Daniels has elite rushing too, he takes a lot of sacks. McCarthy has good (not great) sack avoidance, while Williams and Maye are on the border between good and bad. Rattler's below average in both, which is concerning.


Before moving onto modeling, let's see how draft position tends to NFL success. 15 of the 25 QBs drafted in round 1 become above average NFL starters. Meanwhile, only 4 of the 22 non-first rounders become above average starters. Hurts and Prescott were geniuinely non-first round hits. Purdy still has something to prove after only playing with an elite offense around him. Hill is just efficient on a small sample. These players skew the correlations in recent history, along with first-round busts. However, they will be kept in the sample as we move onto modeling because of the already small sample of QBs in the dataset. Regardless, if NFL teams don't value a QB as a first rounder, this is a bad sign. This will be important when it comes to players like Nix and Penix, as they are fringe first rounders.


**Modeling**

For our train-test split -- not considered last year due to a small sample size -- we will use 85-15. The training set needs to have enough data points, otherwise the results will not be trustworthy. However, our testing results cannot be fully trusted here. While they can provide some small signal, it will likely be very noisy due to a small sample. Thus, we must keep this in mind when doing model selection.

To get an idea of what a good rmse and r^2 might look like, when we use the average (0.547) to predict QB success. We get an rmse of 0.348. This means, on average, we are off by ~35 on a scale from 0-100 (aka percentile).

***Linear Regression***

For the linear regression we can't fit a model with all the potential predictors, because of dimensional issues. Therefore, we start by fitting one with predictors where their absolute correlations are 0.275 or more. Then, by optimizing using the greedy algorithm this gives us the following: an adjusted r^2 of 0.466 and a RMSE of 0.232. The adjusted r^2 is very good and the error is not bad, but collinearity is a problem. Hence, it is not smart to consider this model in the model selection later now.


This model considers predictors with an absolute correlation above 0.30. When optimizing, again with the greedy algorithm, the adjusted r^2 is 0.343 and the error is 0.260. There numbers are both good. The diagnostics pass here, so this is an improvement over the last model. The predictors selected here are average ground EPA, total EPA, and PTSR.


Using the maximum total ground EPA as the only predictor, we get an RMSE of 0.34. The adjusted r^2 is 0.19, which isn't awful. If we instead use PTSR as the only predictor, the r^2 drops to 0.05, but the error improves to 0.31. When using draft pick, both r^2 and RMSE are bad -- 0.01 and 0.33 respectively. Considering these factors, I will try to construct a model which has a high adjusted r^2, low RMSE, and low collinearity error. This will not be perfect, and is not recommended as it will introduce bias, although it will be an interesting exercise.


Again, this process is not ideal, but I looked at the top correlations and did trial and error to optimize r^2 and the prediction error. I ended up with PTSR, average ground EPA, ADOT in first year, and total EPA in best year as the predictors. (Total EPA in best year had a high correlation with round and a better trade off with the comparision metrics.) This model has a adjusted r^2 of 0.321, rmse of 0.240, and low collinearity. If I run the greedy algorithm on this model, it suggests to drop total EPA in best year. This would improve the r^2 to 0.326, but the rmse would worsen to 0.251. Thus, we will keep this predictor considering the better rmse and the tell of overall play, on top of pocket awareness and arm strength. 



***Lasso***



We will next consider a lasso regression, as not all of these predictors should be included due to their massive collinearity.

After completing Lasso, this tells us that no predictors are worth keeping. The intercept (0.53) is what the model will predict each time. By doing so, the error is 0.353; this is worse than our average model.


***KNN***

The prediction error for KNN was optimized at K = 22. This led to an error of 0.343, again not great.


***Random Forest***

After tuning on mtry and nodesize, the selected model has an r^2 of 0.031, with an OOB rate of 0.082. The rmse is bad too at 0.386. So, while this model won't be selected, the top variables for this model include EPA totals, ADOT, and completion percentage (CP).


***XGBoost***


The best prediction error for XGBoost also does not perform with an error of 0.366. The optimal tuning here was 0.1 ETA, 5 max depth, and 2 ntrees.


**Model Selection**



Across the board, most models perform very similarly. Looking at adjusted r^2, the first linear regression (which included all predictors with an abs. correlation of 0.275 or higher) is by far the best at 0.466. However, there are certainly overfitting issues as the model does not pass the collineartiy diagnostics. Next tier here is the second and third linear regression respectively. These have good r^2s, but not great at around a third. 

For prediction error, the baseline is 0.348 for the average. Five models did perform better than this. The best here was the first linear regression, however note the collinearity issues. Next comes the other linear regression models, with this time the third performing slightly better. With the testing sample size being so small, this rmse statistic should be taken with a grain of salt though.

Therefore, we will select the second linear regression model, with hesitancy. This model has the second highest adjusted r^2 and the third lowest prediction error. The first LR model would have been chosen, but it did not pass the collinearity diagnostics. Meanwhile, the third linear regression model does have a better rmse, however the more stable stat (r^2) is worse than the second LR. On top of this, bias was introudced when modeling the third linear regression. The runners up are the average, the best predictor, and the KNN model. The best predictor and KNN model each had a slightly better prediction error than the average. Although that is the case, the errors are all close enough that the average is probably the best of the runner ups. The advanced models all didn't perform well. This can possibly be improved by transforming the predictors into principal components. However, it is not necessary as the advanced models all pass the diagnostics by tuning them.

**Projections**

Let's see how the selected model projects the 2024 NFL draft prospects!


Nix and Penix are in their own tier due to their elite pocket awareness and experience. The issue with both is their consensus rankings have them as fringe first rounders. Considering this, if they fall out of the first round, they shouldn't necessarily be looked at as values. The top-4 on the consensus board are next at slightly above average. McCarthy is hurt by his limited number of plays, same with Williams and Maye, but Daniels is helped by it. Tak on the fact that all have had elite seasons makes them good prospects. The biggest issue is Daniels needs a good surrounding as his PTSR is concerning low. Daniels' experience and rushing should help him though. Williams and Maye weren't elite in pocket awareness in college, but their elite production make them elite prospects regardless. McCarthy was great across the board, but it was on a small sample, as stated earlier. On the other hand, Rattler projects poorly being worst in every category but PTSR.

Some late round QBs are interesting. Jordan Travis has the third highest projection (77th percentile) out of the 11 prospects considered, due to his experience and good (not great) pocket awareness. The other three (Hartman, Pratt, and Milton) all project as below average starter or backup. Hartman and Pratt are helped by their production & experience, but hurt by their pocket awareness, which is concerning. Milton might be worth a flyer with his strong arm and decent pocket awareness.


**Conclusion**

Next steps include using a larger sample, implementing principal components into the models, and adding even more predictors. The first is by far the most important, as having a larger sample size will almost certainly create a better model than using the average. Implementing PCs will help the advanced models perform better. More predictors, like performance in a clean pocket, on play action plays, or percentage of pressures assigned to the QB will likely have some significance. Regardless, this analysis is a big step forward from last year's and provides us with a more concrete projection of the QB prospects. One continued theme is the stability of pocket awareness. Metrics like PTSR and ground EPA need to be considered more when ranking prospects. 

Thanks for reading!




``` {r, include = FALSE}

# Necessary Libraries
library(cfbfastR)
library(nflreadr)
library(ggrepel)
library(tidyverse)
library(caTools)
library(car)
library(lmtest)
library(glmnet)
library(kknn)
library(randomForestSRC)
library(xgboost)
library(gt)



nfl_qbs_season = read_csv("qb-performances-06-23.csv")[, -1]

df_final = read_csv("qb-college-stats-2024")[, -1]

draft_picks = load_draft_picks()


```


``` {r, include = FALSE}

nfl_qbs = nfl_qbs_season |> 
  filter(!is.na(qbr_pct_tot)) |> 
  select(player, qbr_pct_tot:plays_tot) |> 
  unique() |> 
  rename(nfl_pct = qbr_pct_tot,
         mean_epa = mean_epa_tot,
         mean_grade = grade_avg,
         plays = plays_tot) |> 
  arrange(-nfl_pct)

# # All-Time ELite
# nfl_qbs |> filter(plays >= 1000)
# 
# # Best here
# nfl_qbs
# 
# # Average (40th - 60th Percentile)
# nfl_qbs |> 
#   filter(nfl_pct <= .6 & nfl_pct >= .4)
# 
# # Poor (<= 10th percentile)
# nfl_qbs |> 
#   filter(nfl_pct <= .15)

```











``` {r, echo = FALSE}

# NQBR

cor_df = cor(
  df_final |> 
  filter(!is.na(nfl_pct)) |>
  select(-player)
  )

# cor_df |> View()

cor_tbl = as_tibble(cor_df) |> 
  mutate(names = colnames(cor_df)) |> 
  dplyr::select(names, everything()) |> 
  filter(names != "nfl_pct")
# cor_tbl |>
#   select(names, nfl_pct) |>
#   arrange(-abs(nfl_pct))
# cor_tbl

ggplot(cor_tbl
       |> filter(abs(nfl_pct) >= .25)
       , aes(x = abs(nfl_pct), y = reorder(names, abs(nfl_pct)))) +
  geom_col(aes(fill = nfl_pct > 0), alpha = .8) +
  labs(
    title = "Absolute Correlation with NFL nQBR",
    subtitle = "min. 0.25 abs. correlation  |  blue = positive / red = negative  |  nqbr = 50-50 composite of epa/play & pff grade",
    y = "Predictors",
    x = "Correlation",
    caption = "By: Sam Burch  |  Data: nflfastR, cfbfastR, & pff (2014-2023)",
    fill = element_blank()
  ) +
  scale_x_continuous(breaks = seq(0, 1, .1)) +
  scale_fill_brewer(palette = "Set1") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5, size = 6),
        axis.line = element_line(color = "black", size = 0.5),
        panel.grid.major.x = element_line(color = "lightgray", size = 0.5, linetype = 2),  # Customize vertical major grid lines
        panel.grid = element_blank(),
        panel.background = element_blank(),
        legend.position = "none")

# ggsave("nqbr-predictors-correlation.png", width = 16, height = 16, units = "cm")


```

 



``` {r, echo = FALSE}

# Picks



cor_df_2 = cor(
  df_final |> 
  filter(!is.na(nfl_pct)) |>
  select(-player)
  )

# cor_df |> View()

cor_tbl_2 = as_tibble(cor_df_2) |> 
  mutate(names = colnames(cor_df_2)) |> 
  dplyr::select(names, everything()) |> 
  filter(names != "pick", names != "round")
# cor_tbl_2 |>
#   select(names, pick) |>
#   arrange(-abs(pick))
# cor_tbl

ggplot(cor_tbl_2
       |> filter(abs(pick) >= .4)
       , aes(x = abs(pick), y = reorder(names, abs(pick)))) +
  geom_col(aes(fill = pick > 0), alpha = .8) +
  labs(
    title = "Absolute Correlation with Draft Pick",
    subtitle = "round removed  |  min. 0.40 abs. correlation  |  blue = positive / red = negative  |  nqbr = 50-50 composite of epa/play & pff grade",
    y = "Predictors",
    x = "Correlation",
    caption = "By: Sam Burch  |  Data: nflfastR, cfbfastR, & pff (2014-2023)",
    fill = element_blank()
  ) +
  scale_x_continuous(breaks = seq(0, 1, .1)) +
  scale_fill_brewer(palette = "Set1") + 
  theme(plot.title = element_text(hjust = 0.5),
        plot.subtitle = element_text(hjust = 0.5, size = 6),
        axis.line = element_line(color = "black", size = 0.5),
        panel.grid.major.x = element_line(color = "lightgray", size = 0.5, linetype = 2),  # Customize vertical major grid lines
        panel.grid = element_blank(),
        panel.background = element_blank(),
        legend.position = "none")

# ggsave("round-predictors-correlation.png", width = 16, height = 16, units = "cm")


```








``` {r, eval = FALSE}

# College Production Career

df_final |> filter(
         # player == "Anthony Richardson" |
         # player == "Will Levis" |
         
         player == "Caleb Williams" |
         player == "Drake Maye" |
         player == "Jayden Daniels" |
         player == "Bo Nix" |
         player == "Michael Penix Jr." |
         player == "J.J. McCarthy" |
         player == "Spencer Rattler" |
           !is.na(nfl_pct),
         off_grade_avg >= 70,
         mean_epa_tot >= 0
         ) |> 
  ggplot(aes(y = mean_epa_tot, x = off_grade_avg)) +
  labs(
    title = "QB College Production (Career)",
    subtitle = "outliers (Kyle Allen & Trevor Siemian) removed  |  blue = above average starter  | red = below average  |  gray = prospect",
    x = "Avg. PFF Grade",
    y = "EPA / Play",
    caption = "By: Sam Burch  |  Data: nflfastR, pff, and cfbfastR"
  ) +
  geom_point(aes(color = nfl_pct >= .67)) +
  geom_text_repel(size = 2, aes(label = player)) +
  stat_smooth(formula = y ~ x, method = 'lm', geom = 'line', se=FALSE, color='grey30', linetype = 2, alpha = .3) +
  nflplotR::geom_mean_lines(aes(y0 = mean_epa_tot, x0 = off_grade_avg), alpha = .3) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, size = 7),
    axis.line = element_line(color = "black", size = 0.5),
    panel.grid = element_blank(),
    panel.background = element_blank(),
    legend.position = "none"
  )

# ggsave("college-qb-career-production.png", width = 16, height = 9, units = "cm")


```

Looking at career production, Williams is atop, with Maye being second in grading and McCarthy being second in efficiency. While good production in college doesn't necessarily translate to NFL production -- look at the mix of blue and red dots in the top right and bottom left -- we know that production is important for draft position. Thus, with draft position being important historically, we know college production should lead to better prospects in general.



``` {r, eval = FALSE}


# Best College Production

df_final |> filter(
         # player == "Anthony Richardson" |
         # player == "Will Levis" |
         
         player == "Caleb Williams" |
         player == "Drake Maye" |
         player == "Jayden Daniels" |
         player == "Bo Nix" |
         player == "Michael Penix Jr." |
         player == "J.J. McCarthy" |
         player == "Spencer Rattler" |
           !is.na(nfl_pct),
         off_grade_avg >= 70,
         mean_epa_tot >= 0
         ) |> 
  ggplot(aes(y = mean_epa_max, x = off_grade_max)) +
  labs(
    title = "QB College Production (Best Season)",
    subtitle = "outliers (Kyle Allen & Trevor Siemian) removed  |  blue = above average starter  | red = below average  |  gray = prospect",
    x = "PFF Grade",
    y = "EPA / Play",
    caption = "By: Sam Burch  |  Data: nflfastR, pff, and cfbfastR"
  ) +
  geom_point(aes(color = nfl_pct >= .67)) +
  geom_text_repel(size = 1.5, aes(label = player)) +
  stat_smooth(formula = y ~ x, method = 'lm', geom = 'line', se=FALSE, color='grey30', linetype = 2, alpha = .3) +
  nflplotR::geom_mean_lines(aes(y0 = mean_epa_max, x0 = off_grade_max), alpha = .3) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, size = 7),
    axis.line = element_line(color = "black", size = 0.5),
    panel.grid = element_blank(),
    panel.background = element_blank(),
    legend.position = "none"
  )

# ggsave("college-qb-max-production.png", width = 16, height = 9, units = "cm")

```

Looking at best season production for efficiency and grading, Daniels is by far the best of the 24' prospects. Nix is second, followed by a cluster including Williams, Penix, and McCarthy. Maye & Rattler had elite grading in their best seasons, but efficiency was below average here. Regardless, all of these prospects have had good best seasons, which should be a good sign.


``` {r, eval = FALSE}

# Ground vs. Air EPA

df_final |> filter(
         # player == "Anthony Richardson" |
         # player == "Will Levis" |
         
         player == "Caleb Williams" |
         player == "Drake Maye" |
         player == "Jayden Daniels" |
         player == "Bo Nix" |
         player == "Michael Penix Jr." |
         player == "J.J. McCarthy" |
         player == "Spencer Rattler" |
           !is.na(nfl_pct)
         # off_grade_avg >= 70
         ) |> 
  ggplot(aes(avg_ground_epa_tot, avg_pass_epa_tot)) +
  labs(
    title = "Ground vs. Air EPA in College",
    subtitle = "blue = above average starter  | red = below average  |  gray = prospect",
    y = "EPA / Pass",
    x = "EPA / (Rush + Sack)",
    caption = "By: Sam Burch  |  Data: nflfastR, pff, and cfbfastR"
  ) +
  # scale_y_reverse() +
  geom_point(aes(color = nfl_pct >= .67)) +
  geom_text_repel(size = 2, aes(label = player)) +
  stat_smooth(formula = y ~ x, method = 'lm', geom = 'line', se=FALSE, color='grey30', linetype = 2, alpha = .3) +
  nflplotR::geom_mean_lines(aes(x0 = avg_ground_epa_tot, y0 = avg_pass_epa_tot), alpha = .3) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, size = 8),
    axis.line = element_line(color = "black", size = 0.5),
    panel.grid = element_blank(),
    panel.background = element_blank(),
    legend.position = "none"
  )

# ggsave("college-qb-ground-vs-air.png", width = 16, height = 9, units = "cm")


```

Here, we look at where on the field a QBs efficiency is coming from. The top right (good passing, rushing, and sack avoidance) is where one wants to be. Of the NFL QBs, only three are below average and six are above average. All of the 24' prospects, expect Rattler, are in this quadrant. Also, having good ground efficiency gives QBs a solid floor, since very few above average starters had below average ground efficiency and 8 of the top 9 were above average starters. Nix and Daniels show up the best in ground efficiency giving them a solid floor. Keep in mind though, some of the *successful* QBs with great ground EPA include Hill and Mariota.


``` {r, eval = FALSE}

# Best Predictors Comp

df_final |> filter(
         # player == "Anthony Richardson" |
         # player == "Will Levis" |
         
         player == "Caleb Williams" |
         player == "Drake Maye" |
         player == "Jayden Daniels" |
         player == "Bo Nix" |
         player == "Michael Penix Jr." |
         player == "J.J. McCarthy" |
         player == "Spencer Rattler" |
           !is.na(nfl_pct)
         ) |> 
  ggplot(aes(y = adot_first, x = total_ground_epa_max)) +
  labs(
    title = "Top 2 Predictors from College to Pro",
    subtitle = "correlation of 0.42 & 0.37 for ground epa and adot respectively  |  blue = above average starter  | red = below average  |  gray = prospect",
    y = "ADOT in First Year",
    x = "Max Total Ground (Rush + Sack) EPA",
    caption = "By: Sam Burch  |  Data: nflfastR, pff, and cfbfastR"
  ) +
  geom_point(aes(color = nfl_pct >= .67)) +
  geom_text_repel(size = 1.8, aes(label = player)) +
  stat_smooth(formula = y ~ x, method = 'lm', geom = 'line', se=FALSE, color='grey30', linetype = 2, alpha = .3) +
  nflplotR::geom_mean_lines(aes(y0 = adot_first, x0 = total_ground_epa_max), alpha = .3) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, size = 6.5),
    axis.line = element_line(color = "black", size = 0.5),
    panel.grid = element_blank(),
    panel.background = element_blank(),
    legend.position = "none"
  )


# ggsave("college-qb-best-predictors-comp.png", width = 16, height = 9, units = "cm")



```

The top couple predictors are all dealing with ground efficiency. However, ADOT in a QBs first year is very high as well. As we compare the two, we can see there have only been three failures in the top right quadrant, compared to nine successes.  Williams, McCarthy, Maye, and Penix are all in this area. Nix and Daniels don't have a high ADOT in their first year, however they have the second and third best max total ground EPA respectively. Again, this should lead to a high floor and is a good sign regardless of their ADOT.


``` {r, eval = FALSE}

# How QBs Deal with Pressure

df_final |> filter(
         # player == "Anthony Richardson" |
         # player == "Will Levis" |
         
         player == "Caleb Williams" |
         player == "Drake Maye" |
         player == "Jayden Daniels" |
         player == "Bo Nix" |
         player == "Michael Penix Jr." |
         player == "J.J. McCarthy" |
         player == "Spencer Rattler" |
           !is.na(nfl_pct)
         ) |> 
  ggplot(aes(avg_ground_epa_tot, pressure_to_sack_rate_tot)) +
  labs(
    title = "How QBs Deal with Pressure in College",
    subtitle = "blue = above average starter  | red = below average  |  gray = prospect",
    y = "PTSR",
    x = "EPA / (Rush + Sack)",
    caption = "By: Sam Burch  |  Data: nflfastR, pff, and cfbfastR"
  ) +
  scale_y_reverse() +
  geom_point(aes(color = nfl_pct >= .67)) +
  geom_text_repel(size = 2, aes(label = player)) +
  stat_smooth(formula = y ~ x, method = 'lm', geom = 'line', se=FALSE, color='grey30', linetype = 2, alpha = .3) +
  nflplotR::geom_mean_lines(aes(x0 = avg_ground_epa_tot, y0 = pressure_to_sack_rate_tot), alpha = .3) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, size = 8),
    axis.line = element_line(color = "black", size = 0.5),
    panel.grid = element_blank(),
    panel.background = element_blank(),
    legend.position = "none"
  )

# ggsave("college-qb-best-pressure-performance.png", width = 16, height = 9, units = "cm")


```

Just looking at how QBs deal with pressure in college can tell us a lot. Penix has the best PTSR in this entire dataset. Nix also doesn't take many sacks and has the added benefit of his rushing. While Daniels has elite rushing too, he takes a lot of sacks. McCarthy has good (not great) sack avoidance, while Williams and Maye are on the border between good and bad. Rattler's below average in both, which is concerning.



``` {r, include = FALSE}

# How QBs Deal with Pressure

df_final |> filter(
         # player == "Anthony Richardson" |
         # player == "Will Levis" |
         
         # player == "Caleb Williams" |
         # player == "Drake Maye" |
         # player == "Jayden Daniels" |
         # player == "Bo Nix" |
         # player == "Michael Penix Jr." |
         # player == "J.J. McCarthy" |
         # player == "Spencer Rattler" |
           !is.na(nfl_pct)
         ) |> 
  # mutate(round = if_else(round == 8, "Undrafted", round)) |> 
  ggplot(aes(round, nfl_pct)) +
  geom_hline(yintercept = .67, alpha = .3, color = "grey30", linetype = 2) +
  labs(
    title = "Draft Round vs. NFL Percentile (2014-2023)",
    subtitle = "gray line is average starter  |  8th round is undrafted  |  percenitle is 50/50 composite of epa/play and pff grade",
    y = "Percentile",
    x = "Round",
    caption = "By: Sam Burch  |  Data: nflfastR, pff, and cfbfastR"
  ) +
  geom_point(color = "skyblue") +
  # geom_text_repel(size = 1, aes(label = player)) +
  scale_x_continuous(breaks = seq(8, 1, -1)) +
  # scale_x_reverse() +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, size = 7),
    axis.line = element_line(color = "black", size = 0.5),
    panel.grid = element_blank(),
    panel.background = element_blank(),
    legend.position = "none"
  )

ggsave("round-predicting-nfl-success.png", width = 16, height = 9, units = "cm")


df_final |> filter(!is.na(nfl_pct), round != 1) |> select(nfl_pct) |> summarise(nfl_pct >= .67) |> sum()




```


Before moving onto modeling, let's see how draft position tends to NFL success. 15 of the 25 QBs drafted in round 1 become above average NFL starters. Meanwhile, only 4 of the 22 non-first rounders become above average starters. Hurts and Prescott were geniuinely non-first round hits. Purdy still has something to prove after only playing with an elite offense around him. Hill is just efficient on a small sample. These players skew the correlations in recent history, along with first-round busts. However, they will be kept in the sample as we move onto modeling because of the already small sample of QBs in the dataset. Regardless, if NFL teams don't value a QB as a first rounder, this is a bad sign. This will be important when it comes to players like Nix and Penix, as they are fringe first rounders.






# Modeling



``` {r, include = FALSE}

df_final_no_name = df_final |> filter(!is.na(nfl_pct)) |> select(-player)

n = nrow(df_final_no_name)


set.seed(123)

# Need Training & Testing to be decent size
train_ind = sample(1:n, .85*n)

train_data = df_final_no_name[train_ind, ]
test_data = df_final_no_name[-train_ind, ]


# full_y = df_final_no_name |> select(nfl_pct) |> pull()
# train_y = full_y[train_ind]
# test_y = full_y[-train_ind]


```



## Linear Regression


``` {r, include = FALSE}

# Baseline, average
(avg_nfl_pct = df_final_no_name |> select(nfl_pct) |> pull() |> mean())
sqrt(mean((rep(avg_nfl_pct, 8) - test_data |> select(nfl_pct) |> pull())^2))
# Benchmark error
```

To get an idea of what a good RMSE and r^2 might look like, when we use the average (0.547) to predict QB success. We get an rmse of 0.348. This means, on average, we are off by ~35 on a scale from 0-100 (aka percentile).






``` {r, echo = FALSE}
top_predictors = cor_tbl |>
  arrange(-nfl_pct) |> 
  filter(abs(nfl_pct) >= .275) |> 
  select(names) |> 
  pull()

m1a = lm(nfl_pct ~ ., data = train_data[, c(top_predictors, "nfl_pct")])
summary(m1a)

m2a = step(m1a)
summary(m2a)

pred = predict(m2a, newdata = test_data)

sqrt(mean((pred - test_data |> select(nfl_pct) |> pull())^2))


sqrt(vif(m2a))
## Above 3, so bad


## All
par(mfrow = c(2, 2))
plot(m2a)

## HIPs
sort(cooks.distance(m2a), decreasing = TRUE)[1:10]
### All good, since less than 1.

## Constant Variance
bptest(m2a)
### With the p-value = .9112 > .05 = $\alpha$, we fail to reject the null and conclude the constant variance assumption is satisfied.

## Normaility, n < 50
shapiro.test(m2a$residuals)
### With the p-value = .798 > .05 = $\alpha$, we fail to reject the null and conclude the normality assumption is satisfied.







```

For the linear regression we can't fit a model with all the potential predictors, because of dimensional issues. Therefore, we start by fitting one with predictors where their absolute correlations are 0.275 or more. Then, by optimizing using the greedy algorithm this gives us the following: an adjusted r^2 of 0.466 and a rmse of 0.232. The adjusted r^2 is very good and the error is not bad, but collinearity is a problem. Hence, it is not smart to consider this model in the model selection later now.


``` {r, echo = FALSE}
top_predictors = cor_tbl |> 
  arrange(-nfl_pct) |> 
  filter(abs(nfl_pct) >= .3) |> 
  select(names) |> 
  pull()

m1b = lm(nfl_pct ~ ., data = train_data[, c(top_predictors, "nfl_pct")])
summary(m1b)

m2b = step(m1b)
summary(m2b)

pred = predict(m2b, newdata = test_data)

sqrt(mean((pred - test_data |> select(nfl_pct) |> pull())^2))


sqrt(vif(m2b))
## Looks Good



## All
par(mfrow = c(2, 2))
plot(m2b)

## HIPs
sort(cooks.distance(m2b), decreasing = TRUE)[1:10]
### All good, since less than 1.

## Constant Variance
bptest(m2b)
### With the p-value = .753 > .05 = $\alpha$, we fail to reject the null and conclude the constant variance assumption is satisfied.

## Normaility, n < 50
shapiro.test(m2b$residuals)
### With the p-value = .376 > .05 = $\alpha$, we fail to reject the null and conclude the normality assumption is satisfied.



```

This model considers predictors with an absolute correlation above 0.30. When optimizing, again with the greedy algorithm, the adjusted r^2 is 0.343 and the error is 0.260. There numbers are both good. The diagnostics pass here, so this is an improvement over the last model. The predictors selected here are average ground EPA, total EPA, and PTSR.






``` {r, echo = FALSE}

m3a = lm(nfl_pct ~ total_ground_epa_max, data = train_data)
summary(m3a)


m3b = lm(nfl_pct ~ pressure_to_sack_rate_tot, data = train_data)
summary(m3b)


m3c = lm(nfl_pct ~ pick, data = train_data)
summary(m3c)



pred = predict(m3c, newdata = test_data)

sqrt(mean((pred - test_data |> select(nfl_pct) |> pull())^2))




```

Using the maximum total ground EPA as the only predictor, we get an RMSE of 0.34. The adjusted r^2 is 0.19, which isn't awful. If we instead use PTSR as the only predictor, the r^2 drops to 0.05, but the error improves to 0.31. When using draft pick, both r^2 and RMSE are bad -- 0.01 and 0.33 respectively. Considering these factors, I will try to construct a model which has a high adjusted r^2, low RMSE, and low collinearity error. This will not be perfect, and is not recommended as it will introduce bias, although it will be an interesting exercise.


``` {r, echo = FALSE}
m3 = lm(nfl_pct ~ pressure_to_sack_rate_tot + avg_ground_epa_tot + adot_first + total_epa_max, data = train_data)
summary(m3)

step(m3)
## Replace with just TDs for no collinearity

pred = predict(m3, newdata = test_data)

sqrt(mean((pred - test_data |> select(nfl_pct) |> pull())^2))

## Collinearity
sqrt(vif(m3))

## All
par(mfrow = c(2, 2))
plot(m3)

## HIPs
sort(cooks.distance(m3), decreasing = TRUE)[1:10]
### All good, since less than 1.

## Constant Variance
bptest(m3)
### With the p-value = .9843 > .05 = $\alpha$, we fail to reject the null and conclude the constant variance assumption is satisfied.

## Normaility, n < 50
shapiro.test(m3$residuals)
### With the p-value = .3279 > .05 = $\alpha$, we fail to reject the null and conclude the normality assumption is satisfied.


```


Again, this process is not ideal, but I looked at the top correlations and did trial and error to optimize r^2 and the prediction error. I ended up with PTSR, average ground EPA, ADOT in first year, and total EPA in best year as the predictors. (Total EPA in best year had a high correlation with round and a better trade off with the comparision metrics.) This model has a adjusted r^2 of 0.321, rmse of 0.240, and low collinearity. If I run the greedy algorithm on this model, it suggests to drop total EPA in best year. This would improve the r^2 to 0.326, but the rmse would worsen to 0.251. Thus, we will keep this predictor considering the better rmse and the tell of overall play, on top of pocket awareness and arm strength. 





We will next consider a lasso regression, as not all of these predictors should be included due to their massive collinearity.


``` {r, echo = FALSE}

### Lasso



set.seed(123)

x_train = as.matrix(train_data |> select(-nfl_pct))
y_train = as.matrix(train_data$nfl_pct)

x_test = as.matrix(test_data |> select(-nfl_pct))
y_test = as.matrix(test_data$nfl_pct)

lasso_model = glmnet(x_train, y_train, alpha = 1)


# Perform cross-validation to select lambda
cv_lasso = cv.glmnet(x_train, y_train, alpha = 1)  # alpha = 1 for Lasso regression
plot(cv_lasso)

# Print optimal lambda value
print(cv_lasso$lambda.min)

coefficients = coef(lasso_model, s = cv_lasso$lambda.min)
coefficients

# Example predictions
pred = predict(lasso_model, newx = x_test, s = cv_lasso$lambda.min)

sqrt(mean((pred - y_test)^2))





```

After completing Lasso, this tells us that no predictors are worth keeping. The intercept (0.53) is what the model will predict each time. By doing so, the error is 0.353; this is worse than our average model.


``` {r, echo = FALSE}
### KNN



error = numeric(35)

set.seed(123)

for (i in 1:35) {
  
  knn.fit = kknn(nfl_pct ~ ., train = train_data, 
                 test = test_data |> dplyr::select(-nfl_pct),
                 k = i, kernel = "rectangular")
  
  test.pred = knn.fit$fitted.values
  
  error[i] = sqrt(mean((test.pred - (test_data |> dplyr::select(nfl_pct) |> pull()))^2))
  
  
}

min(error)

which.min(error)


```

The prediction error for KNN was optimized at K = 22. This led to an error of 0.343, again not great.


``` {r, echo = FALSE}
### Random Forrest
# CHANGED BACK FROM PCS


set.seed(123)
# Random Forests

train_data

# train_data$qbr_nfl
m1 = rfsrc(nfl_pct ~ ., data = as.data.frame(train_data))
# OOB Error Rate
tail(m1$err.rate, 1)


tuning_grid = expand.grid(mtry = c(1, 5, 10, 15, 20), nodesize = c(1, 5, 10, 15, 20))
tuned_models = vector(mode = "list", length = 25)
oob_error_rates = numeric(25)
set.seed(123)
for (i in 1:nrow(tuning_grid)) {
  rf_model = rfsrc(nfl_pct ~ ., data = as.data.frame(train_data),
  mtry = tuning_grid[i, 1], nodesize = tuning_grid[i, 2])
  tuned_models[[i]] = rf_model
  oob_error_rates[i] = tail(rf_model$err.rate, 1)
}
# OOB ER for each model
oob_error_rates


# Find the index of the minimum OOB error rate
best_index = which.min(oob_error_rates)
# Best tuning parameters
best_tuning = tuning_grid[best_index, ]
best_tuning

# Extract the random forest model with the best tuning parameters
best_rf_model = tuned_models[[best_index]]
best_rf_model


# Calculate the variable importance for the best model
variable_importance = vimp(best_rf_model)
sort(abs(variable_importance$importance), decreasing = TRUE)

### TTR


pred_rf = predict(best_rf_model, newdata = as.data.frame(test_data))

sqrt(mean((pred_rf$predicted - as.vector(y_test))^2))



```

After tuning on mtry and nodesize, the selected model has an r^2 of 0.031, with an OOB rate of 0.082. The rmse is bad too at 0.386. So, while this model won't be selected, the top variables for this model include EPA totals, ADOT, and completion percentage (CP).


``` {r, echo = FALSE}
### XGBoost

x_train = as.matrix(train_data |> select(-nfl_pct))
y_train = as.matrix(train_data$nfl_pct)
x_test = as.matrix(test_data |> select(-nfl_pct))
y_test = as.matrix(test_data$nfl_pct)



set.seed(123)

train_data_xgb = xgb.DMatrix(data = data.matrix(train_data |> select(-nfl_pct)), label = train_data$nfl_pct)
test_data_xgb = xgb.DMatrix(data = data.matrix(test_data |> select(-nfl_pct)), label = test_data$nfl_pct)

params = list(
  objective = "reg:squarederror",
  # num_class = 10, # Number of classes
  eta = 0.5, # Learning rate
  max_depth = 2 # Maximum depth of trees
)

num_round = 50


xgb.fit = xgb.train(params, train_data_xgb, num_round)


pred_xgb = predict(xgb.fit, newdata = test_data_xgb)

sqrt(mean((pred_xgb - as.vector(y_test))^2))
## Bad




tuning_grid2 = expand.grid(eta = c(0.1, 0.5, 1.0), max_depth = c(2, 5, 10))


best_eta = c(numeric(9))
best_max_depth = c(numeric(9))
best_ntrees = c(numeric(9))
best_error = c(rep(1, 9))

set.seed(123)

# Loop over the search space
for (i in 1:nrow(tuning_grid2)) {
  # Set the xgboost parameters
  params = list(
    objective = "reg:squarederror",
    # num_class = 10,
    eta = tuning_grid2[i, 1],
    max_depth = tuning_grid2[i, 2]
  )
  
  train_data_xgb = xgb.DMatrix(data = data.matrix(train_data |> select(-nfl_pct)), label = train_data$nfl_pct)
  test_data_xgb = xgb.DMatrix(data = data.matrix(test_data |> select(-nfl_pct)), label = test_data$nfl_pct)
  
  num_round = 50
  
  bst = xgb.train(params, train_data_xgb, num_round)
  
  for (j in 1:50) {
    pred_xgb = predict(bst, test_data_xgb, iterationrange = c(1, j))
    
    # sqrt(mean((pred_xgb - as.vector(y_test))^2))
    # Calculate the testing error
    error = sqrt(mean((pred_xgb - as.vector(y_test))^2))
    
    # Update the best parameters and the corresponding testing error
    if (error < best_error[i]) {
      best_eta[i] = tuning_grid2[i, 1]
      best_max_depth[i] = tuning_grid2[i, 2]
      best_ntrees[i] = j
      best_error[i] = error
    }
    
  }
}

(results = data.frame(best_eta, best_max_depth, best_ntrees, best_error))

# Best Error
results[which.min(best_error), ]







```

The best prediction error for XGBoost also does not perform with an error of 0.366. The optimal tuning here was 0.1 ETA, 5 max depth, and 2 ntrees.


``` {r, echo = FALSE}
## Model selection



all_models = tibble(model = c("Average", "Best Predictor", "Linear Regression 1", "Linear Regression 2", "Linear Regression 3", "Lasso", "KNN", "Random Forest", "XGBoost"),
       r_2 = c(NA, 0.188, 0.466, 0.343, 0.321, NA, NA, 0.034, NA),
       rmse = c(0.348, 0.343, 0.232, 0.260, 0.240, 0.353, 0.346, 0.384, 0.366),
       diagnostics = c("Yes", "Yes", "No", "Yes", "Yes*", "Yes", "Yes", "Yes", "Yes"))





model_summary = all_models |> 
  gt() |> 
  tab_header(title = "QB Model Selection") |> 
  tab_footnote("By: Sam Burch") |> 
  cols_label(
    model = "Model Type",
    r_2 = "Adjusted R^2",
    rmse = "RMSE",
    diagnostics = "Passed Diagnostics"
  ) |> 
  cols_align("center")



# gtsave(data = model_summary, filename = "qb-model-summary.png")





```


Across the board, most models perform very similarly. Looking at adjusted r^2, the first linear regression (which included all predictors with an abs. correlation of 0.275 or higher) is by far the best at 0.466. However, there are certainly overfitting issues as the model does not pass the collineartiy diagnostics. Next tier here is the second and third linear regression respectively. These have good r^2s, but not great at around a third. 

For prediction error, the baseline is 0.348 for the average. Five models did perform better than this. The best here was the first linear regression, however note the collinearity issues. Next comes the other linear regression models, with this time the third performing slightly better. With the testing sample size being so small, this rmse statistic should be taken with a grain of salt though.

Therefore, we will select the second linear regression model, with hesitancy. This model has the second highest adjusted r^2 and the third lowest prediction error. The first LR model would have been chosen, but it did not pass the collinearity diagnostics. Meanwhile, the third linear regression model does have a better rmse, however the more stable stat (r^2) is worse than the second LR. On top of this, bias was introudced when modeling the third linear regression. The runners up are the average, the best predictor, and the KNN model. The best predictor and KNN model each had a slightly better prediction error than the average. Although that is the case, the errors are all close enough that the average is probably the best of the runner ups. The advanced models all didn't perform well. This can possibly be improved by transforming the predictors into principal components. However, it is not necessary as the advanced models all pass the diagnostics by tuning them.



Let's see how the selected model projects the 2024 NFL draft prospects!




``` {r, echo = FALSE}

df_final_no_nfl = df_final |> filter(is.na(nfl_pct)) |>
  mutate(pick = case_when(
    # Jack Lich Big Board Avg.
            player == "Caleb Williams" ~ 1.92,
            player == "Drake Maye" ~ 4,
            player == "Jayden Daniels" ~ 12.17,
            player == "Bo Nix" ~ 39.5,
            player == "Michael Penix Jr." ~ 43.17,
            player == "J.J. McCarthy" ~ 29.25,
            player == "Spencer Rattler" ~ 83,
            player == "Michael Pratt" ~ 108.1,
            player == "Jordan Travis" ~ 148.5,
            player == "Joe Milton III" ~ 196.2,
            player == "Sam Hartman" ~ 234.71,
            .default = pick)) |> 
  mutate(round = case_when(
    # Jack Lich Big Board Avg.
            player == "Caleb Williams" ~ 1,
            player == "Drake Maye" ~ 1,
            player == "Jayden Daniels" ~ 1,
            player == "Bo Nix" ~ 2,
            player == "Michael Penix Jr." ~ 2,
            player == "J.J. McCarthy" ~ 1,
            player == "Spencer Rattler" ~ 3,
            player == "Michael Pratt" ~ 4,
            player == "Jordan Travis" ~ 5,
            player == "Joe Milton III" ~ 6,
            player == "Sam Hartman" ~ 7,
            .default = pick))

# Projections
projections = predict(m2b, newdata = df_final_no_nfl)

top_upcoming_qbs = df_final_no_nfl |> 
  mutate(nfl_pct_proj = projections) |>
  filter(
         # player == "Anthony Richardson" |
         # player == "Will Levis" |
         
         player == "Caleb Williams" |
         player == "Drake Maye" |
         player == "Jayden Daniels" |
         player == "Bo Nix" |
         player == "Michael Penix Jr." |
         player == "J.J. McCarthy" |
         player == "Spencer Rattler"
           
         # player == "Michael Pratt" |
         # player == "Jordan Travis" |
         # player == "Joe Milton III" |
         # player == "Sam Hartman"
         ) |> 
  # select(player, nfl_pct_proj, pressure_to_sack_rate_tot, adot_first) |> 
  select(player, nfl_pct_proj, avg_ground_epa_tot, total_epa_tot, pressure_to_sack_rate_tot
         # off_grade_avg, mean_epa_tot, pressure_to_sack_rate_tot, adot_first, avg_ground_epa_tot
         ) |>
  arrange(-nfl_pct_proj)
# top_upcoming_qbs

ggplot(top_upcoming_qbs, aes(x = reorder(player, nfl_pct_proj), y = nfl_pct_proj)) +
  geom_col(aes(color = player, fill = player)) +
  labs(
    x = element_blank(),
    y = 'nQBR Percentile Projection',
    title = 'Final 2024 Draft QB Projections',
    subtitle = "r^2 = 0.343  |  rmse = .260  |  gray line is average starter  |  linear regression model based on total EPA, PTSR, & ground EPA  |  nqbr = 50/50 compsite of EPA/play and PFF grade",
    caption = "By: Sam Burch  |  Data: nflfastR, cfbfastR, & pff"
  ) +
  scale_y_continuous(breaks = seq(0, 1, .1)) +
  geom_hline(yintercept =  .67, color = 'grey30', linetype = 2) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, size = 5),
    plot.caption = element_text(size = 6),
    axis.line = element_line(color = "black", size = 0.5),
    axis.text.x = element_text(size = 7),
    axis.text.y = element_text(size = 7),
    panel.grid = element_blank(),
    panel.background = element_blank(),
    legend.position = "none"
  )

# ggsave("qb_proj_24.png", width = 16, height = 9, units = "cm")



```


**Takeaways from projections**

Nix and Penix are in their own tier due to their elite pocket awareness and experience. The issue with both is their consensus rankings have them as fringe first rounders. Considering this, if they fall out of the first round, they shouldn't necessarily be looked at as values. The top-4 on the consensus board are next at slightly above average. McCarthy is hurt by his limited number of plays, same with Williams and Maye, but Daniels is helped by it. Tak on the fact that all have had elite seasons makes them good prospects. The biggest issue is Daniels needs a good surrounding as his PTSR is concerning low. Daniels' experience and rushing should help him though. Williams and Maye weren't elite in pocket awareness in college, but their elite production make them elite prospects regardless. McCarthy was great across the board, but it was on a small sample, as stated earlier. On the other hand, Rattler projects poorly being worst in every category but PTSR.

Some late round QBs are interesting. Jordan Travis has the third highest projection (77th percentile) out of the 11 prospects considered, due to his experience and good (not great) pocket awareness. The other three (Hartman, Pratt, and Milton) all project as below average starter or backup. Hartman and Pratt are helped by their production & experience, but hurt by their pocket awareness, which is concerning. Milton might be worth a flyer with his strong arm and decent pocket awareness.


**Conclusion**

Next steps include using a larger sample, implementing principal components into the models, and adding even more predictors. The first is by far the most important, as having a larger sample size will almost certainly create a better model than using the average. Implementing PCs will help the advanced models perform better. More predictors, like performance in a clean pocket, on play action plays, or percentage of pressures assigned to the QB will likely have some significance. Regardless, this analysis is a big step forward from last year's and provides us with a more concrete projection of the QB prospects. One continued theme is the stability of pocket awareness. Metrics like PTSR and ground EPA need to be considered more when ranking prospects. 

Thanks for reading!





# OLD / Unecessary

first aspect of building the model is determining what NFL success is. Ben Baldwin stated "[about] 95% of [how good a QB is can be determined from] looking at EPA (expected points added) and PFF (Pro Football Focus) grade." So, we will use this as our indicator of QB play in the NFL.

``` {r, warning = FALSE, message = FALSE, eval = FALSE, echo = FALSE}
# Names
name_23 = load_player_stats(2023)
name_22 = load_player_stats(2022)
name_21 = load_player_stats(2021)
name_20 = load_player_stats(2020)
name_19 = load_player_stats(2019)
name_18 = load_player_stats(2018)
name_17 = load_player_stats(2017)
name_16 = load_player_stats(2016)
name_15 = load_player_stats(2015)
name_14 = load_player_stats(2014)
name_13 = load_player_stats(2013)
name_12 = load_player_stats(2012)
name_11 = load_player_stats(2011)
name_10 = load_player_stats(2010)
name_09 = load_player_stats(2009)
name_08 = load_player_stats(2008)
name_07 = load_player_stats(2007)
name_06 = load_player_stats(2006)

qb_names = name_23 |> 
  full_join(name_22) |> 
  full_join(name_21) |> 
  full_join(name_20) |> 
  full_join(name_19) |> 
  full_join(name_18) |> 
  full_join(name_17) |> 
  full_join(name_16) |> 
  full_join(name_15) |> 
  full_join(name_14) |> 
  full_join(name_13) |> 
  full_join(name_12) |> 
  full_join(name_11) |> 
  full_join(name_10) |> 
  full_join(name_09) |> 
  full_join(name_08) |> 
  full_join(name_07) |> 
  full_join(name_06) |> 
  filter(position == 'QB') |> 
  select(player_id, player_display_name) |>
  unique()

```


## PBP

``` {r, cache = TRUE, eval = FALSE, echo = FALSE}
pbp_nfl = load_pbp(2006:2023)
```


``` {r, eval = FALSE, echo = FALSE}
pbp_nfl = pbp_nfl |> 
  mutate(split_game_id = str_split(game_id, '_', simplify = TRUE),
         year_id = as.double(split_game_id[,1]))

# Define qb_names from below first!

qb_ids = qb_names |> select(player_id) |> pull()

pbp_nfl_2 = pbp_nfl |> 
  filter(!is.na(yards_gained), (pass == 1 & (passer_id %in% qb_ids)) 
         | (rush == 1 & (rusher_id %in% qb_ids))) |> 
  mutate(passer_new = case_when(!is.na(passer) ~ passer, !is.na(rusher) ~ rusher)) |> 
  mutate(passer_id_new = case_when(!is.na(passer) ~ passer_id, !is.na(rusher) ~ rusher_id)) |> 
  group_by(passer_new, passer_id_new) |> 
  summarise(mean_epa = mean(epa, na.rm = TRUE),
            ypa = mean(yards_gained),
            sack_rate = mean(sack),
            cpoe = mean(cpoe, na.rm = TRUE),
            plays = n(),
            .groups = 'drop') |>
  # CHANGED FROM 650
  ## What minimum?
  filter(plays >= 400) |> 
  arrange(-mean_epa)
pbp_nfl_2

pbp_nfl_3 = pbp_nfl |>
  filter(!is.na(yards_gained), (pass == 1 & (passer_id %in% qb_ids)) 
         | (rush == 1 & (rusher_id %in% qb_ids))) |> 
  mutate(passer_new = case_when(!is.na(passer) ~ passer, !is.na(rusher) ~ rusher)) |> 
  mutate(passer_id_new = case_when(!is.na(passer) ~ passer_id, !is.na(rusher) ~ rusher_id)) |> 
  group_by(passer_new, passer_id_new, year_id) |> 
  summarise(mean_epa = mean(epa, na.rm = TRUE),
            plays = n(),
            .groups = 'drop') |>
  # CHANGED FROM 650
  ## What minimum?
  filter(plays >= 150) |> 
  arrange(-year_id, -mean_epa) |> 
  select(passer_new, passer_id_new, year_id, mean_epa)




```


## PFF

``` {r, warning = FALSE, message = FALSE, eval = FALSE, echo = FALSE}

pff_nfl_23 = read_csv('pff_qb_nfl_23.csv')
pff_nfl_22 = read_csv('pff_qb_nfl_22.csv')
pff_nfl_21 = read_csv('pff_qb_nfl_21.csv')
pff_nfl_20 = read_csv('pff_qb_nfl_20.csv')
pff_nfl_19 = read_csv('pff_qb_nfl_19.csv')
pff_nfl_18 = read_csv('pff_qb_nfl_18.csv')
pff_nfl_17 = read_csv('pff_qb_nfl_17.csv')
pff_nfl_16 = read_csv('pff_qb_nfl_16.csv')
pff_nfl_15 = read_csv('pff_qb_nfl_15.csv')
pff_nfl_14 = read_csv('pff_qb_nfl_14.csv')
pff_nfl_13 = read_csv('pff_qb_nfl_13.csv')
pff_nfl_12 = read_csv('pff_qb_nfl_12.csv')
pff_nfl_11 = read_csv('pff_qb_nfl_11.csv')
pff_nfl_10 = read_csv('pff_qb_nfl_10.csv')
pff_nfl_09 = read_csv('pff_qb_nfl_09.csv')
pff_nfl_08 = read_csv('pff_qb_nfl_08.csv')
pff_nfl_07 = read_csv('pff_qb_nfl_07.csv')
pff_nfl_06 = read_csv('pff_qb_nfl_06.csv')

pff_nfl_23 = pff_nfl_23 |> 
  mutate(year_id = 2023)
pff_nfl_22 = pff_nfl_22 |> 
  mutate(year_id = 2022)
pff_nfl_21 = pff_nfl_21 |> 
  mutate(year_id = 2021)
pff_nfl_20 = pff_nfl_20 |> 
  mutate(year_id = 2020)
pff_nfl_19 = pff_nfl_19 |> 
  mutate(year_id = 2019)
pff_nfl_18 = pff_nfl_18 |> 
  mutate(year_id = 2018)
pff_nfl_17 = pff_nfl_17 |> 
  mutate(year_id = 2017)
pff_nfl_16 = pff_nfl_16 |> 
  mutate(year_id = 2016)
pff_nfl_15 = pff_nfl_15 |> 
  mutate(year_id = 2015)
pff_nfl_14 = pff_nfl_14 |> 
  mutate(year_id = 2014)
pff_nfl_13 = pff_nfl_13 |> 
  mutate(year_id = 2013)
pff_nfl_12 = pff_nfl_12 |> 
  mutate(year_id = 2012)
pff_nfl_11 = pff_nfl_11 |> 
  mutate(year_id = 2011)
pff_nfl_10 = pff_nfl_10 |> 
  mutate(year_id = 2010)
pff_nfl_09 = pff_nfl_09 |> 
  mutate(year_id = 2009)
pff_nfl_08 = pff_nfl_08 |> 
  mutate(year_id = 2008)
pff_nfl_07 = pff_nfl_07 |> 
  mutate(year_id = 2007)
pff_nfl_06 = pff_nfl_06 |> 
  mutate(year_id = 2006)

pff_nfl = pff_nfl_23 |> 
  full_join(pff_nfl_22) |> 
  full_join(pff_nfl_21) |> 
  full_join(pff_nfl_20) |> 
  full_join(pff_nfl_19) |> 
  full_join(pff_nfl_18) |> 
  full_join(pff_nfl_17) |> 
  full_join(pff_nfl_16) |> 
  full_join(pff_nfl_15) |> 
  full_join(pff_nfl_14) |> 
  full_join(pff_nfl_13) |> 
  full_join(pff_nfl_12) |> 
  full_join(pff_nfl_11) |> 
  full_join(pff_nfl_10) |> 
  full_join(pff_nfl_09) |> 
  full_join(pff_nfl_08) |> 
  full_join(pff_nfl_07) |> 
  full_join(pff_nfl_06)


# Key Stats by year
pff_nfl_2 = pff_nfl |> 
  mutate(player_id = as.character(player_id)) |>
  select(player_id, player, year_id, grades_offense, pressure_to_sack_rate, avg_time_to_throw, dropbacks) |> 
  mutate(player = case_when(player == "Robert Griffin III" ~ "Robert Griffin",
                                       player == "Michael Vick" ~ "Mike Vick",
                                       player == "E.J. Manuel" ~ "EJ Manuel",
                            .default = player))


# Totals of what we need -- average PFF grade
pff_nfl_3 = pff_nfl_2 |> 
  # Change?
  filter(dropbacks >= 150) |>
  group_by(player_id, player) |>
  summarise(grade_avg = mean(grades_offense),
            .groups = 'drop') |> 
  arrange(-grade_avg)
pff_nfl_3


pff_nfl_4 = pff_nfl_2 |> 
  filter(dropbacks >= 150) |> 
  arrange(-year_id, -grades_offense) |> 
  select(player, player_id, year_id, grades_offense, dropbacks)
pff_nfl_4





```



## Full NFL Dataset

``` {r, eval = FALSE, echo = FALSE}
# Adding grade and names to dataset
nfl_qbs = pbp_nfl_2 |>
  left_join(qb_names, by = c('passer_id_new' = 'player_id')) |> 
  select(-passer_new, player_display_name, passer_id_new:plays) |> 
  left_join(pff_nfl_3, by = c('player_display_name' = 'player')) |> 
  select(player_display_name, everything(), -c(passer_id_new, player_id)) |> 
  filter(!is.na(grade_avg)) |> 
  # Combined EPA and Grade to make new QBR metric
  mutate(qbr = .5*scale(mean_epa) + .5*scale(grade_avg)) |> 
  mutate(qbr_pct = pnorm(qbr)) |> 
  select(player_display_name, qbr, qbr_pct, mean_epa, grade_avg, everything()) |> 
  arrange(-qbr)
nfl_qbs

nfl_qbs_2 = pbp_nfl_3 |>
  left_join(qb_names, by = c('passer_id_new' = 'player_id')) |> 
  select(player_display_name, year_id, mean_epa) |> 
  left_join(pff_nfl_4, by = c('player_display_name' = 'player', "year_id")) |> 
  select(-player_id) |> 
  rename(year = year_id,
         player = player_display_name) |>
  mutate(qbr = .5*scale(mean_epa) + .5*scale(grades_offense)) |>
  mutate(qbr_pct = pnorm(qbr)) |> 
  select(player, year, qbr_pct, mean_epa:dropbacks) |> 
  arrange(-qbr_pct)


# Comparison of EPA and Grade
ggplot(nfl_qbs, aes(y = mean_epa, x = grade_avg)) +
  labs(
    title = 'NFL QB EPA against PFF Grade (Averages)',
    subtitle = 'Data from 2006-2023; Min 400 NFL plays; Min 150 dropbacks per season',
    caption = 'By: Sam Burch  |  Data @nflfastR & @pff',
    y = 'EPA per play',
    x = 'Average PFF Grade'
  ) + 
  geom_point() +
  theme_minimal()
cor(nfl_qbs$mean_epa, nfl_qbs$grade_avg)

```




``` {r, eval = FALSE, echo = FALSE}

pbp_cfb = load_cfb_pbp(2014:2023)

# pbp_cfb_23 = load_cfb_pbp(2023)

```


``` {r, eval = FALSE, echo = FALSE}

pbp_cfb |> colnames() |> sort()

pbp_cfb |> 
  select(year) |> 
  unique()

qbs_college = pbp_cfb |>
  group_by(passer_player_name) |>
  summarise(plays = n()) |>
  filter(plays >= 100,
         !is.na(passer_player_name)) |>
  pull(passer_player_name) |>
  unique()


# Just want EPA data here, as we will be using the PFF dataset mainly
cfb_epa = pbp_cfb |>
  filter(!is.na(yards_gained), pass == 1 | (rush == 1 & (rusher_player_name %in% qbs_college)),
         # !is.na(passer_player_name),
         # passer_player_name != "incomplete"
         ) |> 
  mutate(passer_player_name = if_else(rush == 1, rusher_player_name, passer_player_name)) |> 
  group_by(passer_player_name, year) |> 
  summarise(mean_epa = mean(EPA, na.rm = TRUE),
            total_epa = sum(EPA, na.rm = TRUE),
            avg_pass_epa = mean(EPA[pass == 1], na.rm = TRUE),
            total_pass_epa = sum(EPA[pass == 1], na.rm = TRUE),
            avg_rush_epa = mean(EPA[rush == 1], na.rm = TRUE),
            total_rush_epa = sum(EPA[pass == 1], na.rm = TRUE),
            avg_sack_epa = mean(EPA[sack == 1], na.rm = TRUE),
            total_sack_epa = sum(EPA[sack == 1], na.rm = TRUE),
            avg_ground_epa = mean(EPA[rush == 1 | sack == 1], na.rm = TRUE),
            total_ground_epa = sum(EPA[rush == 1 | sack == 1], na.rm = TRUE),

            passes = sum(pass == 1),
            rushes = sum(rush == 1),
            sacks = sum(sack == 1),
            plays = n(),
            
            .groups = "drop") |> 
  # Change to 150?
  filter(plays >= 100) |> 
  group_by(passer_player_name) |> 
  summarise(# Career
            mean_epa_tot = sum(total_epa) / sum(plays),
            total_epa_tot = sum(total_epa),
            avg_pass_epa_tot = sum(total_pass_epa) / sum(passes),
            total_pass_epa_tot = sum(total_pass_epa),
            avg_rush_epa_tot = sum(total_rush_epa) / sum(passes),
            total_rush_epa_tot = sum(total_rush_epa),
            avg_sack_epa_tot = sum(total_sack_epa) / sum(sacks),
            total_sack_epa_tot = sum(total_sack_epa),
            avg_ground_epa_tot = sum(total_ground_epa) / (sum(sacks) + sum(rushes)),
            total_ground_epa_tot = sum(total_ground_epa),
            
            # Totals
            passes_tot = sum(passes),
            rushes_tot = sum(rushes),
            sacks_tot = sum(sacks),
            plays_tot = sum(plays),
            
            # Lasts
            mean_epa_last = mean_epa[year == max(year)],
            total_epa_last = total_epa[year == max(year)],
            avg_pass_epa_last = avg_pass_epa[year == max(year)],
            total_pass_epa_last = total_pass_epa[year == max(year)],
            avg_rush_epa_last = avg_rush_epa[year == max(year)],
            total_rush_epa_last = total_rush_epa[year == max(year)],
            avg_sack_epa_last = avg_sack_epa[year == max(year)],
            total_sack_epa_last = total_sack_epa[year == max(year)],
            avg_ground_epa_last = avg_ground_epa[year == max(year)],
            total_ground_epa_last = total_ground_epa[year == max(year)],
            
            # Firsts
            mean_epa_first = mean_epa[year == min(year)],
            total_epa_first = total_epa[year == min(year)],
            avg_pass_epa_first = avg_pass_epa[year == min(year)],
            total_pass_epa_first = total_pass_epa[year == min(year)],
            avg_rush_epa_first = avg_rush_epa[year == min(year)],
            total_rush_epa_first = total_rush_epa[year == min(year)],
            avg_sack_epa_first = avg_sack_epa[year == min(year)],
            total_sack_epa_first = total_sack_epa[year == min(year)],
            avg_ground_epa_first = avg_ground_epa[year == min(year)],
            total_ground_epa_first = total_ground_epa[year == min(year)],
            
            # Maxes
            mean_epa_max = max(mean_epa),
            total_epa_max = max(total_epa),
            avg_pass_epa_max = max(avg_pass_epa),
            total_pass_epa_max = max(total_pass_epa),
            avg_rush_epa_max = max(avg_rush_epa),
            total_rush_epa_max = max(total_rush_epa),
            avg_sack_epa_max = max(avg_sack_epa),
            total_sack_epa_max = max(total_sack_epa),
            avg_ground_epa_max = max(avg_ground_epa),
            total_ground_epa_max = max(total_ground_epa),
            
            # Mins
            mean_epa_min = min(mean_epa),
            total_epa_min = min(total_epa),
            avg_pass_epa_min = min(avg_pass_epa),
            total_pass_epa_min = min(total_pass_epa),
            avg_rush_epa_min = min(avg_rush_epa),
            total_rush_epa_min = min(total_rush_epa),
            avg_sack_epa_min = min(avg_sack_epa),
            total_sack_epa_min = min(total_sack_epa),
            avg_ground_epa_min = min(avg_ground_epa),
            total_ground_epa_min = min(total_ground_epa),
            
            
            .groups = "drop") |> 
  filter(passer_player_name != "incomplete", !is.na(passer_player_name)) |>
  # Ugh, Mitch Trubisky
  mutate(passer_player_name = if_else(passer_player_name == "Mitch Trubisky", "Mitchell Trubisky", passer_player_name)) |>
  arrange(-mean_epa_tot)
  


cfb_epa |> 
  filter(plays_tot >= 150)



cfb_epa |> filter(passer_player_name == "Mitch Trubisky")



```



## PFF
``` {r, eval = FALSE, echo = FALSE}
pff_cfb_23 = read_csv('pff_qb_cfb_23.csv')
pff_cfb_22 = read_csv('pff_qb_cfb_22.csv')
pff_cfb_21 = read_csv('pff_qb_cfb_21.csv')
pff_cfb_20 = read_csv('pff_qb_cfb_20.csv')
pff_cfb_19 = read_csv('pff_qb_cfb_19.csv')
pff_cfb_18 = read_csv('pff_qb_cfb_18.csv')
pff_cfb_17 = read_csv('pff_qb_cfb_17.csv')
pff_cfb_16 = read_csv('pff_qb_cfb_16.csv')
pff_cfb_15 = read_csv('pff_qb_cfb_15.csv')
pff_cfb_14 = read_csv('pff_qb_cfb_14.csv')

pff_cfb_23 = pff_cfb_23 |> 
  mutate(year_id = 2023)
pff_cfb_22 = pff_cfb_22 |> 
  mutate(year_id = 2022)
pff_cfb_21 = pff_cfb_21 |> 
  mutate(year_id = 2021)
pff_cfb_20 = pff_cfb_20 |> 
  mutate(year_id = 2020)
pff_cfb_19 = pff_cfb_19 |> 
  mutate(year_id = 2019)
pff_cfb_18 = pff_cfb_18 |> 
  mutate(year_id = 2018)
pff_cfb_17 = pff_cfb_17 |> 
  mutate(year_id = 2017)
pff_cfb_16 = pff_cfb_16 |> 
  mutate(year_id = 2016)
pff_cfb_15 = pff_cfb_15 |> 
  mutate(year_id = 2015)
pff_cfb_14 = pff_cfb_14 |> 
  mutate(year_id = 2014)

pff_cfb = pff_cfb_23 |> 
  full_join(pff_cfb_22) |> 
  full_join(pff_cfb_21) |> 
  full_join(pff_cfb_20) |> 
  full_join(pff_cfb_19) |> 
  full_join(pff_cfb_18) |> 
  full_join(pff_cfb_17) |> 
  full_join(pff_cfb_16) |> 
  full_join(pff_cfb_15) |> 
  full_join(pff_cfb_14)
```

## Joining Datasets
``` {r, eval = FALSE, echo = FALSE}
nfl_qbs2 = nfl_qbs |> 
  select(player, nfl_pct)


pff_cfb |> colnames()


df_final = pff_cfb |>
  # Changed from 200
  filter(dropbacks >= 150) |> 
  mutate(tot_ttt = avg_time_to_throw * dropbacks,
         pressure_to_scramble_rate = scrambles / def_gen_pressures,
         scramble_rate = scrambles / dropbacks,
         td_rate = touchdowns / dropbacks,
         int_rate = interceptions / dropbacks,
         bat_rate = bats / attempts,
         hat_rate = hit_as_threw / attempts,
         ta_rate = thrown_aways / dropbacks,
         fd_rate = first_downs / dropbacks,
         pen_rate = penalties / dropbacks) |> 
  group_by(player) |> 
  summarise(#Grades
            off_grade_avg = mean(grades_offense),
            pass_grade_avg = mean(grades_pass),
            run_grade_avg = mean(grades_run),
            fum_grade_avg = mean(grades_hands_fumble),
            
            
            # Totals
            aimed_passes = sum(aimed_passes),
            attempts = sum(attempts),
            dropbacks = sum(dropbacks),
            completions = sum(completions),
            yards = sum(yards),
            tds = sum(touchdowns),
            ints = sum(interceptions),
            sacks = sum(sacks),
            pressures = sum(def_gen_pressures),
            scrambles = sum(scrambles),
            btts = sum(big_time_throws),
            twps = sum(turnover_worthy_plays),
            first_downs = sum(first_downs),
            penalties = sum(penalties),
            bats = sum(bats),
            hats = sum(hit_as_threw),
            tas = sum(thrown_aways),
            
            
            # Efficiecy & Rates
            cp = completions / attempts,
            adj_cp = (completions + sum(drops)) / aimed_passes,
            ypa_tot = yards / attempts,
            sack_rate = sacks / dropbacks,
            pressure_to_sack_rate_tot = sacks / pressures,
            pressure_to_scramble_rate_tot = scrambles / pressures,
            scramble_rate_tot = scrambles / dropbacks,
            ttt = sum(tot_ttt) / dropbacks,
            btt_rate_tot = btts / attempts,
            twp_rate_tot = twps / attempts,
            adot_avg = mean(avg_depth_of_target),
            nfl_pr = 100*(((completions/attempts - .3)*5 + (yards/attempts - 3)*.25 + (tds/attempts)*20 + 2.375 - (ints/attempts)*25)/6),
            td_rate_tot = tds / dropbacks,
            int_rate_tot = ints / dropbacks,
            bat_rate_tot = bats / attempts,
            hat_rate_tot = hats / attempts,
            ta_rate_tot = tas / dropbacks,
            fd_rate_tot = first_downs / dropbacks,
            pen_rate_tot = penalties / dropbacks,
            
            # Maxs (Raw)
            tds_max = max(touchdowns),
            off_grade_max = max(grades_offense),
            pass_grade_max = max(grades_pass),
            run_grade_max = max(grades_run),
            fum_grade_max = max(grades_hands_fumble),
            cp_max = max(completion_percent),
            ## Correct?
            adj_cp_max = max(accuracy_percent),
            ypa_max = max(ypa),
            sack_rate_max = max(sack_percent),
            pressure_to_sack_rate_max = max(pressure_to_sack_rate),
            pressure_to_scramble_rate_max = max(pressure_to_scramble_rate),
            scramble_rate_max = max(scramble_rate),
            ttt_max = max(avg_time_to_throw),
            btt_rate_max = max(btt_rate),
            twp_rate_max = max(twp_rate),
            adot_max = max(avg_depth_of_target),
            nfl_pr_max = max(qb_rating),
            td_rate_max = max(td_rate),
            int_rate_max = max(int_rate),
            bat_rate_max = max(bat_rate),
            hat_rate_max = max(hat_rate),
            ta_rate_max = max(ta_rate),
            fd_rate_max = max(fd_rate),
            pen_rate_max = max(pen_rate),
            
            # Mins (Raw)
            tds_min = min(touchdowns),
            off_grade_min = min(grades_offense),
            pass_grade_min = min(grades_pass),
            run_grade_min = min(grades_run),
            fum_grade_min = min(grades_hands_fumble),
            cp_min = min(completion_percent),
            ## Correct?
            adj_cp_min = min(accuracy_percent),
            ypa_min = min(ypa),
            sack_rate_min = min(sack_percent),
            pressure_to_sack_rate_min = min(pressure_to_sack_rate),
            pressure_to_scramble_rate_min = min(pressure_to_scramble_rate),
            scramble_rate_min = min(scramble_rate),
            ttt_min = min(avg_time_to_throw),
            btt_rate_min = min(btt_rate),
            twp_rate_min = min(twp_rate),
            adot_min = min(avg_depth_of_target),
            nfl_pr_min = min(qb_rating),
            td_rate_min = min(td_rate),
            int_rate_min = min(int_rate),
            bat_rate_min = min(bat_rate),
            hat_rate_min = min(hat_rate),
            ta_rate_min = min(ta_rate),
            fd_rate_min = min(fd_rate),
            pen_rate_min = min(pen_rate),
            
            # Lasts
            tds_last = touchdowns[year_id == max(year_id)],
            off_grade_last = grades_offense[year_id == max(year_id)],
            pass_grade_last = grades_pass[year_id == max(year_id)],
            run_grade_last = grades_run[year_id == max(year_id)],
            fum_grade_last = grades_hands_fumble[year_id == max(year_id)],
            cp_last = completion_percent[year_id == max(year_id)],
            ## Correct?
            adj_cp_last = accuracy_percent[year_id == max(year_id)],
            ypa_last = ypa[year_id == max(year_id)],
            sack_rate_last = sack_percent[year_id == max(year_id)],
            pressure_to_sack_rate_last = pressure_to_sack_rate[year_id == max(year_id)],
            pressure_to_scramble_rate_last = pressure_to_scramble_rate[year_id == max(year_id)],
            scramble_rate_last = scramble_rate[year_id == max(year_id)],
            ttt_last = avg_time_to_throw[year_id == max(year_id)],
            btt_rate_last = btt_rate[year_id == max(year_id)],
            twp_rate_last = twp_rate[year_id == max(year_id)],
            adot_last = avg_depth_of_target[year_id == max(year_id)],
            nfl_pr_last = qb_rating[year_id == max(year_id)],
            td_rate_last = td_rate[year_id == max(year_id)],
            int_rate_last = int_rate[year_id == max(year_id)],
            bat_rate_last = bat_rate[year_id == max(year_id)],
            hat_rate_last = hat_rate[year_id == max(year_id)],
            ta_rate_last = ta_rate[year_id == max(year_id)],
            fd_rate_last = fd_rate[year_id == max(year_id)],
            pen_rate_last = pen_rate[year_id == max(year_id)],
            
            # Firsts
            tds_first = touchdowns[year_id == min(year_id)],
            off_grade_first = grades_offense[year_id == min(year_id)],
            pass_grade_first = grades_pass[year_id == min(year_id)],
            run_grade_first = grades_run[year_id == min(year_id)],
            fum_grade_first = grades_hands_fumble[year_id == min(year_id)],
            cp_first = completion_percent[year_id == min(year_id)],
            ## Correct?
            adj_cp_first = accuracy_percent[year_id == min(year_id)],
            ypa_first = ypa[year_id == min(year_id)],
            sack_rate_first = sack_percent[year_id == min(year_id)],
            pressure_to_sack_rate_first = pressure_to_sack_rate[year_id == min(year_id)],
            pressure_to_scramble_rate_first = pressure_to_scramble_rate[year_id == min(year_id)],
            scramble_rate_first = scramble_rate[year_id == min(year_id)],
            ttt_first = avg_time_to_throw[year_id == min(year_id)],
            btt_rate_first = btt_rate[year_id == min(year_id)],
            twp_rate_first = twp_rate[year_id == min(year_id)],
            adot_first = avg_depth_of_target[year_id == min(year_id)],
            nfl_pr_first = qb_rating[year_id == min(year_id)],
            td_rate_first = td_rate[year_id == min(year_id)],
            int_rate_first = int_rate[year_id == min(year_id)],
            bat_rate_first = bat_rate[year_id == min(year_id)],
            hat_rate_first = hat_rate[year_id == min(year_id)],
            ta_rate_first = ta_rate[year_id == min(year_id)],
            fd_rate_first = fd_rate[year_id == min(year_id)],
            pen_rate_first = pen_rate[year_id == min(year_id)],
            
            
            .groups = 'drop') |> 
  
  left_join(nfl_qbs2, by = c('player')) |> 
  left_join(cfb_epa, by = c("player" = "passer_player_name"))
  # A few player names didn't match up correctly (4)
  # filter(!is.na(mean_epa_tot))
  # filter(!is.na(avg_pass_epa_first), !is.na(avg_pass_epa_last), !is.na(avg_sack_epa_first))




# df_final_file = df_final
# write.csv(df_final_file, file = "qb-college-stats-2024")


cfb_epa |> 
  filter(passer_player_name == "Joe Burrow")


df_final |> 
  filter(!is.na(nfl_pct)) |> 
  unique()


# Best to join by IDs

# df_final |> select(player, mean_epa)
# df_final |> filter(!is.na(nfl_pct)) |> select(player, mean_epa)

```


``` {r, eval = FALSE, echo = FALSE}



draft_picks_red = draft_picks |> select(pfr_player_name, round, pick, age) |>
  mutate(pfr_player_name = if_else(pfr_player_name == "Gardner Minshew II", "Gardner Minshew", pfr_player_name))


df_final_2 = df_final |>
  # adds 2 players when joinging by name
  # fix this later, but shouldn't affect current studies
  left_join(draft_picks_red, by = c("player" = "pfr_player_name")) |> 
  mutate(round = if_else((player == "Kyle Allen") |
                         (player == "Nick Mullens") |
                         (player == "Taylor Heinicke") |
                         (player == "Taysom Hill") |
                         (player == "Tyler Huntley"), 8, round)) |>
  mutate(pick = if_else((player == "Kyle Allen") |
                         (player == "Nick Mullens") |
                         (player == "Taylor Heinicke") |
                         (player == "Taysom Hill") |
                         (player == "Tyler Huntley"), 300, pick)) |>
  mutate(age = case_when((player == "Kyle Allen") ~ 22,
                         (player == "Nick Mullens") ~ 22,
                         (player == "Taylor Heinicke") ~ 22,
                         (player == "Taysom Hill") ~ 27,
                         (player == "Tyler Huntley") ~ 22,
                         .default = age)) |>
  unique()



# df_final_file = df_final_2
# write.csv(df_final_file, file = "qb-college-stats-2024")



```



``` {r, eval = FALSE, echo = FALSE}

prospects = df_final_2 |> 
  filter(player == "Caleb Williams" |
         player == "Drake Maye" |
         player == "Jayden Daniels" |
         player == "Bo Nix" |
         player == "Michael Penix Jr." |
         player == "J.J. McCarthy" |
         player == "Spencer Rattler") |> 
  select(player) |> 
  pull()

df_final_2 |> filter(
         # player %in% prospects | 
           !is.na(nfl_pct),
         off_grade_avg >= 70,
         mean_epa_tot >= 0
         ) |> 
  ggplot(aes(x = total_ground_epa_max, y = nfl_pct)) +
  labs(
    title = "Best Ground EPA Season vs. NFL Success",
    subtitle = "0.42 correlation  |  average starter is 67th percentile  |  percentile = 50/50 compsite of EPA/play and PFF grade",
    caption = "By: Sam Burch  |  Data: nflfastR, pff, & cfbfastR",
    y = "NFL Percentile",
    x = "Max Ground EPA College Season",
    color = "Prospects"
  ) +
  geom_point(color = "skyblue") +
  geom_hline(yintercept = .67, alpha = .3, color = "grey30", linetype = 2) +
  # scale_color_brewer(palette = "Set") + 
  geom_segment(data = df_final_2 |> filter(player %in% prospects),
               aes(x = total_ground_epa_max, xend = total_ground_epa_max, y = 0, yend = 1, color = player),
               alpha = .8,
               linetype = 2,
               size = 1) +
  geom_text_repel(size = 2, aes(label = player)) +
  stat_smooth(formula = y ~ x, method = 'lm', geom = 'line', se=FALSE, color='grey30', linetype = 2, alpha = .3) +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.subtitle = element_text(hjust = 0.5, size = 7),
    axis.line = element_line(color = "black", size = 0.5),
    panel.grid = element_blank(),
    panel.background = element_blank(),
    legend.position = c(.9, 0.35),
    legend.key.size = unit(0.5, "cm"),  # Adjust size of legend color key
    legend.title = element_text(size = 10, face = "bold", margin = margin(b = 5)),  # Customize legend title
    legend.text = element_text(size = 8)  # Customize legend text size
  )

# ggsave("max-ground-epa-nqbr-scatter.png", width = 16, height = 12, units = "cm")

```

``` {r}
# pca = prcomp(df_final_no_name |> dplyr::select(-nfl_pct), scale. = TRUE)
# 
# new_x = pca$x[, 1:20]
# 
# train_x = new_x[train_ind, ]
# test_x = new_x[-train_ind, ]





```


``` {r, include = FALSE, eval = FALSE}


pca = prcomp(train_data |> dplyr::select(-nfl_pct), scale. = TRUE)

plot(pca, type = "l")


nfl_pct = train_data |> dplyr::select(nfl_pct) |> pull()
# pg = train_data |> dplyr::select(pos_group_num) |> pull()


pca_df = as_tibble(pca$x) |> 
  mutate(nfl_pct = nfl_pct) 
# |> 
#   mutate(pos_group_num = pg)

# Add in by position group
ggplot(pca_df, aes(x = PC1, y = PC2
                   # , color = as.factor(pos_group_num)
                   )) +
  geom_point() +
  theme_minimal()

ggplot(pca_df, aes(x = PC21, y = nfl_pct
                   # , color = as.factor(pos_group_num)
                   )) +
  geom_point() +
  # scale_y_continuous(breaks = seq(.5, 6, .5)) +
  theme_minimal()


cor(pca_df)[, length(pca_df)] |> abs() |> sort(decreasing = TRUE)
## PC 21

```






## K-Means

``` {r, eval = FALSE}

set.seed(123)

kmean_result = kmeans(train_data |> select(-c(nfl_pct)), 3)

kmean_result$withinss

train_data_kmean = train_data |> 
  mutate(nfl_pct_cat = case_when((nfl_pct <= .6) ~ 1,
                                 (nfl_pct > .6 & nfl_pct <= .85) ~ 2,
                                 (nfl_pct >.85 ~ 3)))

# kmean_result$cluster

train_data_kmean$cluster = as.factor(kmean_result$cluster)

table(train_data_kmean$cluster, train_data_kmean$nfl_pct_cat)





```










``` {r, eval = FALSE}
### Ridge (Not as useful)

# library(caret)
# library(MASS)
# library(glmnet)
# 
# 
# set.seed(123)
# 
# x_train = as.matrix(train_data |> select(-nfl_pct))  # Standardize predictor variables for training set
# y_train = as.matrix(train_data$nfl_pct)
# 
# x_test = as.matrix(test_data |> select(-nfl_pct))  # Standardize predictor variables for testing set
# y_test = as.matrix(test_data$nfl_pct)


# ridge_model = cv.glmnet(x_train, y_train, alpha = 0)
# 
# plot(ridge_model)
# 
# best_lambda = ridge_model$lambda.min
# 
# final_model = glmnet(x_train, y_train, alpha = 0, lambda = best_lambda)
# 
# sort(abs(final_model$beta), decreasing = TRUE)
# final_model$beta
# 
# pred = predict(final_model, newx = x_test)
# 
# sqrt(mean((pred - y_test)^2))


```
